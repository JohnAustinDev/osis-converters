#! /usr/bin/perl

# To filter CF_addDictLinks.xml so it may produce AI validated links,
# follow these steps:
# 1) Run rankGlossaryTerms to generate prompts_terms which must be
#    one-by-one fed to AI and the results added to the terms.csv file.
# 2) Run rankGlossaryLinks to generate prompts_links which must be
#    one-by-one fed to AI and the results added to the links.csv file.
# 3) Run filterAddDictLinks which reads these two csv files and
#    filters CF_addDictLinks.xml so it will produce valid links.

use strict; use File::Spec; our $SCRIPT = File::Spec->rel2abs(__FILE__); our $SCRD = $SCRIPT; $SCRD =~ s/([\\\/][^\\\/]+){2}$//; require "$SCRD/lib/common/bootstrap.pm"; &init(shift, shift);

use Encode;
use Text::CSV_XS;
use File::Spec;
use XML::LibXML;
use Data::Dumper;

our ($MAININPD, $MAINMOD, $DICTMOD, $XML_PARSER, $XPC);

my $aiPromptLength = &conf('ARG_AiPromptLength') || 100;
my $termsPromptDirName = 'ai_prompt_terms';
my $linksPromtDirName = 'ai_prompt_links';
my $termsCsvName = 'terms.csv';
my $linksCsvName = 'links.csv';

my $termsPromptDir = "$MAININPD/$termsPromptDirName";
my $termsCsv = "$termsPromptDir/$termsCsvName";
my $linksPromptDir = "$MAININPD/$linksPromtDirName";
my $linksCsv = "$linksPromptDir/$linksCsvName";

my $Iso = &conf('Lang'); $Iso =~ s/\-\w+$//;
my $Columns = "\"ISO-639 $Iso glossary term\",\"ISO-639 $Iso link\",\"osisID\",\"Tier\"";

# Read the CSV file into a hash of hashes, and read config
my %rows;
my %config;
my $dataStart = 0;
my $csv = Text::CSV_XS->new({ binary => 1, auto_diag => 1 });
open(my $fh, "<:encoding(utf8)", "$termsCsv") or &Error("$termsCsv: $!", 1, 1, 1);
while (my $row = $csv->getline($fh)) {
  if (@$row[0] eq "ISO-639 $Iso term") {
    $dataStart = 1;
  } elsif ($dataStart) {
    my $ent = @$row[0];
    my $gloss = @$row[1];
    my $class = @$row[2];
    my $count = @$row[3];
    $rows{$ent} = { 'gloss' => $gloss, 'class' => $class, 'count' => $count };
  } else {
    $config{'default'}{@$row[0]} = @$row[1];
  }
}
close $fh;

# Determine which terms are high risk and selected them for AI validation
my %riskyRows; # term => priority
my $rec = $config{'default'}{'term classes requiring validation'};
my $ret = $config{'default'}{'terms requiring validation'};
my $rno = $config{'default'}{'terms not requiring validation'};
foreach my $e (keys %rows) {
  if ($rno && $e =~ /$rno/) {next;}
  if (($rec && $rows{$e}{'class'} =~ /$rec/) || ($ret && $e =~ /$ret/)) {
    $riskyRows{$e} = sprintf("%s %03d", $rows{$e}{'class'}, $rows{$e}{'count'});
  }
}

# Prepare links prompt directory and csv
if (-e glob("$linksPromptDir/*.txt")) {`rm '$linksPromptDir'/*.txt`;}
if (! -e "$linksPromptDir") {`mkdir '$linksPromptDir'`;}
if (! -e "$linksCsv") {
  &shell("echo '\"only link capitalized proper nouns\",\"1\"' > $linksCsv");
  &shell("echo '\"link exact term if term length less than\",\"4\"' >> $linksCsv");
  &shell("echo '\"link exact term if link count greater than\",\"400\"' >> $linksCsv");
  &shell("echo '\"keep link classes\",\"(A|B)\"' >> $linksCsv");
  &shell("echo '\"A\",\"Excellent\"' >> $linksCsv");
  &shell("echo '\"B\",\"Good\"' >> $linksCsv");
  &shell("echo '\"C\",\"Fair\"' >> $linksCsv");
  &shell("echo '\"D\",\"Poor\"' >> $linksCsv");
  &shell("echo '\"\",\"\"' >> $linksCsv");
  &shell("echo '$Columns' >> $linksCsv");
}

# Create verse container OSIS file IF it does not exist (this runs SLOW)
my $mainOutdir = &getModuleOutputDir($MAINMOD);
my $verseContainerOsis = "$linksPromptDir/${MAINMOD}_vc.xml";
my $modosis = "$mainOutdir/$MAINMOD.xml";
if (! -e $verseContainerOsis || -M $verseContainerOsis > -M $modosis) {
  &shell("saxonb-xslt -l -ext:on -xsl:'$SCRD/lib/bible/containers.xsl' -s:'$modosis' -o:'$verseContainerOsis'");
}
if (! -e $verseContainerOsis || -M $verseContainerOsis > -M $modosis) {
  &Error("Missing or out-of-date verse container OSIS file: $verseContainerOsis");
}

# Create AI prompts to scrutinize the link contexts of selected terms
my $dictOutdir = &getModuleOutputDir($DICTMOD);
my $dictosis = "$dictOutdir/$DICTMOD.xml";
foreach my $term (
  sort {$riskyRows{$a} <=> $riskyRows{$b}}
  keys %riskyRows
) {
  my $hP = &readTerm($term, $dictosis);
  my $entryText = $hP->{'text'};
  my $termID = $hP->{'osisID'};

  my $refsAP = &readRefs($termID, $verseContainerOsis);

  my $n = 1;
  my $single = @$refsAP <= $aiPromptLength;
  while (@$refsAP) {
    my @batch = splice(@$refsAP, 0, $aiPromptLength);
    my $path = sprintf("%s/%s prompt %s%s.txt",
      $linksPromptDir,
      $riskyRows{$term},
      $term,
      $single ? '' : '_' . $n . '-' . ($n + @batch - 1)
    );
    if (-e $path) {&Error("Prompt file exists: $path");}
    writePrompt($entryText, \@batch, $path);
    $n += @batch;
  }
}

########################################################################
########################################################################

sub readTerm {
  my $term = shift;
  my $osisdict = shift;

  my $osis = $XML_PARSER->parse_file($osisdict);

  my @kws = $XPC->findnodes(".//osis:div[\@type='x-keyword'][descendant::osis:seg[\@type='keyword'][normalize-space()='$term']]", $osis);
  if (@kws == 1) {
    my $kw = @kws[0];
    $kw = &deleteXpath('.//osis:*[@resp="x-oc"]', $kw);

    my @osisText = $XPC->findnodes('.//osis:osisText', $osis);
    my $m = @osisText[0]->getAttribute('osisRefWork');
    my @entnodes = $XPC->findnodes(
      "descendant::osis:seg[\@type='keyword'][normalize-space()='$term']",
      $kw
    );
    my $entnode = @entnodes[0];
    my $osisID = $m . ':' . $entnode->getAttribute('osisID');

    # Mark our term
    my $termtext = $entnode->textContent();
    $termtext .= ':';
    my $new_node = $osis->ownerDocument->createTextNode($termtext);
    $entnode->replaceNode($new_node);

    my %result;
    $result{'text'} = $kw->textContent();
    $result{'text'} =~ s/^\s+|\s+$//g;
    $result{'text'} =~ s/\s+/ /g;
    $result{'osisID'} = $osisID;
    return \%result;
  } if (@kws > 1) {
    &Error("Too many keywords: $term");
  } else {
    &Error("Failed to find keyword: $term");
  }
}

sub readRefs {
  my $termID = encode('utf8', shift);
  my $osisvc = shift;

  my $osis = $XML_PARSER->parse_file($osisvc);

  my $refxpath = "osis:reference[contains(concat(' ', normalize-space(\@osisRef), ' '), ' $termID ')]";

  my @refNodes = $XPC->findnodes(".//$refxpath", $osis);

  my @refs;
  foreach my $refNode (@refNodes) {
    my @elems = $XPC->findnodes('ancestor::osis:*[@osisID][1]', $refNode);
    if (!@elems) {
      &Error("No osisID ancestor for reference to $termID", 1, 1, 1);
    }
    my $elem = @elems[0];

    # Mark our reference
    my $reftext = $refNode->textContent();
    $reftext =~ s/^(.*?)(\W*)$/*$1*$2/g;
    my $new_node = $elem->ownerDocument->createTextNode($reftext);
    $refNode->replaceNode($new_node);

    $elem = &deleteXpath('.//osis:chapter | .//osis:verse | .//osis:note | .//osis:*[@resp="x-oc"]', $elem);

    # Normalized text
    my $text = $elem->textContent();
    $text =~ s/^\s+|\s+$//g;
    $text =~ s/\s+/ /g;

    # Shorten text to one sentence, if too long
    if (length($text) > 256) {
      $text =~ s/^.*?\.\s+([^\.]*\*[^\*]+\*)/$1/;
      $text =~ s/(\*[^\*]+\*[^\.]*\.).*?$/$1/;
    }

    # Remove note initial reference text
    if ($elem->getAttribute('osisID') =~ /!note/) {
      $text =~ s/^[\s\d\-:]+//;
    }

    # Use only first segment of osisID
    my $osisID = $elem->getAttribute('osisID');
    $osisID =~ s/\s+.*$//;

    push(@refs, $osisID . ": " . $text);
  }
  if (!@refs) {
    &Error("Failed to find references: $termID");
  }

  return \@refs;
}

sub deleteXpath {
  my $xpath = shift;
  my $top = shift;

  my $clone = $top->cloneNode(1);
  foreach my $d ($XPC->findnodes($xpath, $clone)) {$d->unbindNode();}
  return $clone;
}

sub writePrompt {
  my $entryText = shift;
  my $refsAP = shift;
  my $outfile = shift;

  my $result = "We are analyzing links to an ISO-639 $Iso OSIS Bible glossary term.
You are performing glossary link relevance tiering using a locked universal rubric.

This rubric MUST NOT be reinterpreted, optimized, or reconsidered during this run or future runs.
You MUST apply it mechanically and consistently.

Tier A: Excellent. Assign ONLY if ALL are true:
  Exact match between the links's contextual usage and the term's glossary description.
  The links's contextual usage matches the glossary term's part of speech (e.g., noun-to-noun).

Tier B: Good. Assign ONLY if ALL are true:
  The links's contextual usage meaning is largely the same as the glossary term's description, but the glossary covers a broader or narrower scope.
  The links's contextual usage either matches, or there is only a minor grammatical mismatch (e.g., plural vs. singular) compared to the glossary term's part of speech.

Tier C: Fair. Assign ONLY if no other tier's criteria are met.

Tier D: Poor. Assign ONLY if ANY are true:
  Meaning of the links's contextual usage is unrelated to the term's glossary description (e.g., \"bank\" of a river vs. financial bank).
  There is a part of speech mismatch between the links's contexual usage and the glossary term. (e.g., verb-to-noun).

Example of tier A:
  glossary: Time - The Jews considered 6am to be the first hour of the day.
  text: The *time* of the earthquake was the fourth hour.

Example of tier D:
  glossary: Time - The Jews considered 6am to be the first hour of the day.
  text: Let both grow together until the harvest *time*.

Here is the glossary term, always followed by a colon, then its description:

$entryText

Here is a list of OSIS references where links to this term occur:

" . join("\n", @{$refsAP}) . "

Please:

1. Read the glossary description carefully and identify its core semantic domains.
2. Analyze the reference link, which is surrounded by '*' symbols, within its context.
3. Group the references into tiers A through D based on the provided rubric (A=Excellent, B=Good, C=Fair, D=Poor).
4. Explain your reasoning step-by-step before providing the final tier assigments.
5. Format your output as escaped CSV having no heading row and exactly these four columns:
$Columns
6. The \"ISO-639 $Iso glossary term\" value MUST be the exact term from the glossary entry (so it MUST be the same for ALL rows).
7. Use the complete OSIS reference format only (e.g., Gen.7.2!note.n1), not human-readable references.
8. Cross-Check Requirement: Before final output, you must cross-reference your step-by-step reasoning with the final CSV data. If the reasoning identifies a mismatch or a specific tier (e.g., Tier D), the CSV MUST reflect that exact tier. Discrepancies between reasoning and the CSV are a failure of the mechanical application.
9. Provide a copy button so I can copy the output as raw text.

Goal:
To assemble a CSV spreadsheet that will help me determine which links to the glossary should be allowed, and which should not.
";

  if ($outfile) {
    if (open(OUTF, ">:encoding(UTF-8)", "$outfile")) {
      print OUTF $result;
      close(OUTF);
    } else {
      &Error("Could not open output file $outfile.");
    }
  } else {
    &Log($result);
  }
}
